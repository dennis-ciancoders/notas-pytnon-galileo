{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Networks - Forward Propagation\n",
    "================================================\n",
    "\n",
    "Intoducción\n",
    "-----------\n",
    "\n",
    "En este laboratorio, estaremos creando redes neurales desde cero, analizaremos su performance y el uso de formward propagation. Nota: Todas las librerias relacionadas a Deep Learning, ya cuentan con las funciones y procedimientos para la creación de las redes neurales, por tanto, en la practica no sera necesario realizar las redes neurales desde cero. El enfoque de este laboratorio es ayudarte a comprender el comportamiento de las redes neurales.\n",
    "\n",
    "Artificial Neural Networks - Forward Propagation\n",
    "------------------------------------------------\n",
    "\n",
    "Resumen\n",
    "\n",
    "De la ultima clase, podemos recapitular como es que las redes neurales funcionan y la importancia de tener una función de propagación. Aqui esta una red neural que contiene dos inputs, contine una \"hidden layer\" con dos nodos y su respectiva salida.\n",
    "\n",
    "![Neural Network Example](http://cocl.us/neural_network_example)\n",
    "\n",
    "Comencemos por inicializar aleatoriamente los pesos y los sesgos en la red. Tenemos 6 pesos y 3 sesgos, uno para cada nodo en la capa oculta y para cada nodo en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2) # initialize the weights\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2) # initialize the biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el resultado generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15 0.74 0.26 0.53 0.01 0.92]\n",
      "[0.9  0.03 0.96]\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los pesos y los sesgos definidos para la red, calculemos la salida para una entrada dada, $x_1$ and $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5\n",
    "x_2 = 0.85\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos calculando la suma ponderada de las entradas  $z_{1, 1}$, para el primer nodo de la capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El peso de la suma de los inputs para el primer nodo de la capa oculta es: 1.604\n"
     ]
    }
   ],
   "source": [
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "\n",
    "print('El peso de la suma de los inputs para el primer nodo de la capa oculta es: {}'.format(z_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, completa la suma de los pesos de los imputs  $z_{1, 2}$, para el segundo nodo de la capa oculta. Asigna el valor a z_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime la suma de los pesos para z_12.  R[1.0625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El peso de la suma de los inputs para el segundo nodo de la capa oculta es: 0.6105\n"
     ]
    }
   ],
   "source": [
    "print('El peso de la suma de los inputs para el segundo nodo de la capa oculta es: {}'.format(z_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, asumiendo una función de activación sigmoid, calculemos la activación del primer nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La activación del primero nodo a_11 es:  0.8325766980765932\n"
     ]
    }
   ],
   "source": [
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('La activación del primero nodo a_11 es:  {}'.format(a_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula también la activación del segundo nodo. $a_{1, 2}$, para la capa oculta y asignalo a a_12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_12 = 1.0/ (1.0 + np.exp(-z_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime el valor de la función de activacion para el segundo nodo. R[0.7432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La activación del segundo nodo a_12 es:  0.648054850401614\n"
     ]
    }
   ],
   "source": [
    "print('La activación del segundo nodo a_12 es:  {}'.format(a_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estas activaciones servirán como entradas a la capa de salida. Entonces, calculemos la suma ponderada de estas entradas al nodo en la capa de salida. Asigna el valor a z_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime la suma de los pesos del nodo de salida. R[1.0025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma de las entradas en el nodo en la capa de salida es 1.5645362293502507\n"
     ]
    }
   ],
   "source": [
    "print('La suma de las entradas en el nodo en la capa de salida es {}'.format(z_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute the output of the network as the activation of the node in the output layer. Assign the value to a_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime la activación del nodo en la capa de salida que es equivalente a la predicción realizada por la red. R[0.7315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma para el nodo de salida es:  0.827003309039\n"
     ]
    }
   ],
   "source": [
    "print('La suma para el nodo de salida es:  {}'.format(a_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, las redes neuronales para problemas reales se componen de muchas capas ocultas y muchos más nodos en cada capa. Por lo tanto, no podemos continuar haciendo predicciones utilizando este enfoque tan ineficiente de calcular la suma ponderada en cada nodo y la activación de cada nodo manualmente.\n",
    "\n",
    "Para codificar una forma automática de hacer predicciones, generalicemos nuestra red. Una red general tomaría $n$ entradas, tendría muchas capas ocultas, cada capa oculta tendría $m$ nodos y tendría una capa de salida. \n",
    "\n",
    "![red](http://cocl.us/general_neural_network)\n",
    "\n",
    "\n",
    "### Inicialización de la red\n",
    "\n",
    "Definamos la estructura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # inputs\n",
    "num_hidden_layers = 2 # hidden layers\n",
    "m = [2, 2] # nodes in each hidden layer\n",
    "num_nodes_output = 1 # nodes in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que definimos la estructura de la red, sigamos adelante e iniciemos los pesos y los sesgos en la red a números aleatorios. Para poder inicializar los pesos y los sesgos a números aleatorios, necesitaremos importar la libreria Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.14, 0.28]), 'bias': array([0.61])}, 'node_2': {'weights': array([0.94, 0.85]), 'bias': array([0.])}}, 'layer_2': {'node_1': {'weights': array([0.52, 0.55]), 'bias': array([0.49])}, 'node_2': {'weights': array([0.77, 0.16]), 'bias': array([0.76])}}, 'output': {'node_1': {'weights': array([0.02, 0.14]), 'bias': array([0.12])}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "num_nodes_previous = n \n",
    "network = {} # empty network\n",
    "# loop through each layer and randomly initialize the weights and biases\n",
    "\n",
    "for layer in range(num_hidden_layers + 1):     \n",
    "    if layer == num_hidden_layers:     # if output layer \n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:                              # not output layer\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahora con el código anterior, podemos inicializar los pesos y los sesgos pertenecientes a cualquier red de cualquier número de capas ocultas y número de nodos en cada capa. Trabajemos en una función para que podamos ejecutar repetidamente todo este código siempre que queramos construir una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    num_nodes_previous = num_inputs \n",
    "    network = {}\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # output layer \n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias \n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa la función anterior, initialize_network, para crear una red con las siguientes caracteristicas:\n",
    "\n",
    "1. 5 inputs\n",
    "2. 3 hidden layers\n",
    "3. 3 nodos en la primera capa, 2 nodos en la segunda capa y 3 nodos en la tercera capa. \n",
    "4. 1 output layer\n",
    "\n",
    "Almacena la red en la variable small_network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.31, 0.67, 0.47, 0.82, 0.29]), 'bias': array([0.73])}, 'node_2': {'weights': array([0.7 , 0.33, 0.33, 0.98, 0.62]), 'bias': array([0.95])}, 'node_3': {'weights': array([0.77, 0.83, 0.41, 0.45, 0.4 ]), 'bias': array([1.])}}, 'layer_2': {'node_1': {'weights': array([0.18, 0.96, 0.42]), 'bias': array([0.42])}, 'node_2': {'weights': array([0.46, 0.37, 0.47]), 'bias': array([0.04])}}, 'layer_3': {'node_1': {'weights': array([0.08, 0.73]), 'bias': array([0.64])}, 'node_2': {'weights': array([0.03, 0.3 ]), 'bias': array([0.22])}, 'node_3': {'weights': array([0.06, 0.52]), 'bias': array([0.42])}}, 'output': {'node_1': {'weights': array([0.05, 0.57, 0.8 ]), 'bias': array([0.11])}}}\n"
     ]
    }
   ],
   "source": [
    "inputs = 5\n",
    "hidden_layers = 3\n",
    "nodes_hidden = [3, 2, 3]\n",
    "nodes_output = 1\n",
    "small_network = initialize_network(inputs, hidden_layers, nodes_hidden, nodes_output)\n",
    "print(small_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular la suma pondera\n",
    "\n",
    "La suma ponderada en cada nodo se calcula como el producto escalar de las entradas y los pesos más el sesgo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos 5 entradas que podamos alimentar small_network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa la función compute_weighted_sum para obtener las sumas ponderadas para el primer nodo de la primera capa oculta R[1.518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma en el primer nodo de la capa oculta es 1.8319999999999999\n"
     ]
    }
   ],
   "source": [
    "weighted_sum = compute_weighted_sum(inputs, small_network['layer_1']['node_1']['weights'], small_network['layer_1']['node_1']['bias'])\n",
    "\n",
    "print('La suma en el primer nodo de la capa oculta es {}'.format(weighted_sum[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activación del nodo\n",
    "\n",
    "Recuerda que la salida de cada nodo es simplemente una transformación no lineal de la suma ponderada. Usamos funciones de activación para este mapeo. Usemos la función Sigmoid como función de activación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa la función node_activation para obtener la salida del primer nodo en la primer capa oculta. R[1.518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861999811394382"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_activation(weighted_sum[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "\n",
    "La construcción de una red neuronal que puede realizar predicciones es juntar todo. Entonces,  hagamos una función que aplique las funciones compute_weighted_sum y node_activation a cada nodo en la red y propague los datos hasta la capa de salida y genere una predicción para cada nodo en la capa de salida.\n",
    "\n",
    "Pseudo-codigo\n",
    "\n",
    "1. Empezar con capa de inputs\n",
    "2. Calcular la suma ponderada en los nodos de la capa actual.\n",
    "3. Calcular la salida de los nodos de la capa actual.\n",
    "4. Generar la salida de la capa actual para que sea la entrada a la siguiente capa.\n",
    "5. Siguiente capa de la red.\n",
    "6. Repita los pasos 2 a 4 hasta que calculemos la salida de la capa de salida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs \n",
    "        \n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza forward_propagate para la red small_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.862, 0.8711, 0.8888]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.8563, 0.7643]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.7801, 0.6166, 0.7045]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7435]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_propagate(small_network, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pythondata-ElkPyzMM-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5c891cd4f68ef213a7b5f847117269620fea06ca1158fbe611802f31c7ef263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
